{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e57d886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting moabb\n",
      "  Downloading moabb-1.4.3-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy>=2.0 (from moabb)\n",
      "  Downloading numpy-2.4.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: scipy>=1.9.3 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (1.17.0)\n",
      "Requirement already satisfied: mne>=1.10.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (1.11.0)\n",
      "Requirement already satisfied: pandas>=1.5.2 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (2.3.3)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (3.15.1)\n",
      "Requirement already satisfied: matplotlib>=3.6.2 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (3.10.8)\n",
      "Collecting seaborn>=0.12.1 (from moabb)\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyriemann>=0.9 (from moabb)\n",
      "  Downloading pyriemann-0.10-py2.py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: PyYAML>=6.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (6.0.2)\n",
      "Requirement already satisfied: pooch>=1.6.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (1.8.2)\n",
      "Requirement already satisfied: requests>=2.28.1 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (2.32.4)\n",
      "Requirement already satisfied: urllib3>=1.26.15 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (4.67.1)\n",
      "Collecting coverage>=7.0.1 (from moabb)\n",
      "  Downloading coverage-7.13.1-cp311-cp311-macosx_10_9_x86_64.whl.metadata (8.5 kB)\n",
      "Collecting memory-profiler>=0.61.0 (from moabb)\n",
      "  Downloading memory_profiler-0.61.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting edflib-python>=1.0.6 (from moabb)\n",
      "  Downloading EDFlib_Python-1.0.8-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting edfio>=0.4.2 (from moabb)\n",
      "  Downloading edfio-0.4.12-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting pytest>=8.3.5 (from moabb)\n",
      "  Downloading pytest-9.0.2-py3-none-any.whl.metadata (7.6 kB)\n",
      "Requirement already satisfied: mne-bids>=0.16 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (0.18.0)\n",
      "Requirement already satisfied: scikit-learn>=1.6 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from moabb) (1.8.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (3.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from matplotlib>=3.6.2->moabb) (2.9.0.post0)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from memory-profiler>=0.61.0->moabb) (7.2.1)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from mne>=1.10.0->moabb) (5.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from mne>=1.10.0->moabb) (3.1.6)\n",
      "Requirement already satisfied: lazy-loader>=0.3 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from mne>=1.10.0->moabb) (0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from pandas>=1.5.2->moabb) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from pandas>=1.5.2->moabb) (2025.3)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from pooch>=1.6.0->moabb) (4.5.1)\n",
      "Requirement already satisfied: joblib in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from pyriemann>=0.9->moabb) (1.5.3)\n",
      "Collecting iniconfig>=1.0.1 (from pytest>=8.3.5->moabb)\n",
      "  Downloading iniconfig-2.3.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pluggy<2,>=1.5 (from pytest>=8.3.5->moabb)\n",
      "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from pytest>=8.3.5->moabb) (2.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.6.2->moabb) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from requests>=2.28.1->moabb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from requests>=2.28.1->moabb) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from requests>=2.28.1->moabb) (2026.1.4)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from scikit-learn>=1.6->moabb) (3.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/bci_env/lib/python3.11/site-packages (from jinja2->mne>=1.10.0->moabb) (3.0.2)\n",
      "Downloading moabb-1.4.3-py3-none-any.whl (279 kB)\n",
      "Downloading coverage-7.13.1-cp311-cp311-macosx_10_9_x86_64.whl (218 kB)\n",
      "Downloading edfio-0.4.12-py3-none-any.whl (29 kB)\n",
      "Downloading EDFlib_Python-1.0.8-py3-none-any.whl (26 kB)\n",
      "Downloading memory_profiler-0.61.0-py3-none-any.whl (31 kB)\n",
      "Downloading numpy-2.4.1-cp311-cp311-macosx_10_9_x86_64.whl (16.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m  \u001b[33m0:00:12\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyriemann-0.10-py2.py3-none-any.whl (132 kB)\n",
      "Downloading pytest-9.0.2-py3-none-any.whl (374 kB)\n",
      "Downloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
      "Downloading iniconfig-2.3.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: pluggy, numpy, memory-profiler, iniconfig, coverage, pytest, edflib-python, edfio, seaborn, pyriemann, moabb\n",
      "\u001b[2K  Attempting uninstall: numpy\n",
      "\u001b[2K    Found existing installation: numpy 1.26.4\n",
      "\u001b[2K    Uninstalling numpy-1.26.4:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/11\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-1.26.4━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/11\u001b[0m [numpy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [moabb]m10/11\u001b[0m [moabb]ann]hon]r]\n",
      "\u001b[1A\u001b[2KSuccessfully installed coverage-7.13.1 edfio-0.4.12 edflib-python-1.0.8 iniconfig-2.3.0 memory-profiler-0.61.0 moabb-1.4.3 numpy-2.4.1 pluggy-1.6.0 pyriemann-0.10 pytest-9.0.2 seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install moabb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaaac16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bci_env/lib/python3.11/site-packages/moabb/datasets/download.py:60: RuntimeWarning: Setting non-standard config type: \"MNE_DATASETS_BNCI_PATH\"\n",
      "  set_config(key, get_config(\"MNE_DATA\"))\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03T.mat' to file '/Users/parkkangho/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03T.mat'.\n",
      "/opt/miniconda3/envs/bci_env/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bnci-horizon-2020.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/bci_env/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 44.1M/44.1M [00:00<00:00, 30.9GB/s]\n",
      "SHA256 hash of downloaded file: 7e731ee8b681d5da6ecb11ae1d4e64b1653c7f15aad5d6b7620b25ce53141e80\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A03E.mat' to file '/Users/parkkangho/mne_data/MNE-bnci-data/database/data-sets/001-2014/A03E.mat'.\n",
      "/opt/miniconda3/envs/bci_env/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bnci-horizon-2020.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/envs/bci_env/lib/python3.11/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████| 42.3M/42.3M [00:00<00:00, 46.9GB/s]\n",
      "SHA256 hash of downloaded file: d4229267ec7624fa8bd3af5cbebac17f415f7c722de6cb676748f8cb3b717d97\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    }
   ],
   "source": [
    "from braindecode.datasets import MOABBDataset\n",
    "\n",
    "subject_id = 3\n",
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[subject_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b75d9fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat' to file 'C:\\Users\\qkrrk\\mne_data\\MNE-bnci-data\\database\\data-sets\\001-2014\\A01T.mat'.\n",
      "c:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bnci-horizon-2020.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "  6%|##2                                  | 2.66M/42.8M [00:02<00:26, 1.52MB/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbraindecode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MOABBDataset\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbraindecode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      9\u001b[39m     Anonymize,\n\u001b[32m     10\u001b[39m     ApplyHilbert,\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m     preprocess,\n\u001b[32m     18\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m dataset = \u001b[43mMOABBDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBNCI2014_001\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\braindecode\\datasets\\moabb.py:161\u001b[39m, in \u001b[36mMOABBDataset.__init__\u001b[39m\u001b[34m(self, dataset_name, subject_ids, dataset_kwargs, dataset_load_kwargs)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m moabb_version == \u001b[33m\"\u001b[39m\u001b[33m1.0.0\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    156\u001b[39m     warnings.warn(\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmoabb version 1.0.0 generates incorrect annotations. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease update to another version, version 0.5 or 1.1.0 \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    159\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m raws, description = \u001b[43mfetch_data_with_moabb\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubject_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_load_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_load_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m all_base_ds = [\n\u001b[32m    168\u001b[39m     RawDataset(raw, row) \u001b[38;5;28;01mfor\u001b[39;00m raw, (_, row) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(raws, description.iterrows())\n\u001b[32m    169\u001b[39m ]\n\u001b[32m    170\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(all_base_ds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\braindecode\\datasets\\moabb.py:120\u001b[39m, in \u001b[36mfetch_data_with_moabb\u001b[39m\u001b[34m(dataset_name, subject_ids, dataset_kwargs, dataset_load_kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m         dataset = dataset_name\n\u001b[32m    119\u001b[39m subject_id = [subject_ids] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(subject_ids, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m subject_ids\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fetch_and_unpack_moabb_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubject_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_load_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_load_kwargs\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\braindecode\\datasets\\moabb.py:41\u001b[39m, in \u001b[36m_fetch_and_unpack_moabb_data\u001b[39m\u001b[34m(dataset, subject_ids, dataset_load_kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_fetch_and_unpack_moabb_data\u001b[39m(dataset, subject_ids=\u001b[38;5;28;01mNone\u001b[39;00m, dataset_load_kwargs=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     40\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dataset_load_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m         data = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     43\u001b[39m         data = dataset.get_data(subjects=subject_ids, **dataset_load_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\base.py:519\u001b[39m, in \u001b[36mBaseDataset.get_data\u001b[39m\u001b[34m(self, subjects, cache_config, process_pipeline)\u001b[39m\n\u001b[32m    517\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m subject \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.subject_list:\n\u001b[32m    518\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mInvalid subject \u001b[39m\u001b[38;5;132;01m{:d}\u001b[39;00m\u001b[33m given\u001b[39m\u001b[33m\"\u001b[39m.format(subject))\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     data[subject] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_single_subject_data_using_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprocess_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    524\u001b[39m check_subject_names(data)\n\u001b[32m    525\u001b[39m check_session_names(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\base.py:614\u001b[39m, in \u001b[36mBaseDataset._get_single_subject_data_using_cache\u001b[39m\u001b[34m(self, subject, cache_config, process_pipeline)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;66;03m# Load and eventually overwrite:\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cached_steps) == \u001b[32m0\u001b[39m:  \u001b[38;5;66;03m# last option: we don't use cache\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     sessions_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_single_subject_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    615\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m sessions_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# should not happen\u001b[39;00m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\bnci.py:891\u001b[39m, in \u001b[36mMNEBNCI._get_single_subject_data\u001b[39m\u001b[34m(self, subject)\u001b[39m\n\u001b[32m    889\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_single_subject_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, subject):\n\u001b[32m    890\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return data for a single subject.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m891\u001b[39m     sessions = \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    892\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m sessions\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-482>:10\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(subject, dataset, path, force_update, update_path, base_url, only_filenames, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\bnci.py:117\u001b[39m, in \u001b[36mload_data\u001b[39m\u001b[34m(subject, dataset, path, force_update, update_path, base_url, only_filenames, verbose)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m dataset_list.keys():\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    113\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDataset \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not a valid BNCI dataset ID. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    114\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mValid dataset are \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m % (dataset, \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(dataset_list.keys()))\n\u001b[32m    115\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdataset_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_update\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupdate_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbaseurl_list\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43monly_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-484>:10\u001b[39m, in \u001b[36m_load_data_001_2014\u001b[39m\u001b[34m(subject, path, force_update, update_path, base_url, only_filenames, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\bnci.py:206\u001b[39m, in \u001b[36m_load_data_001_2014\u001b[39m\u001b[34m(subject, path, force_update, update_path, base_url, only_filenames, verbose)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m session_idx, r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mE\u001b[39m\u001b[33m\"\u001b[39m]):\n\u001b[32m    205\u001b[39m     url = \u001b[33m\"\u001b[39m\u001b[38;5;132;01m{u}\u001b[39;00m\u001b[33m001-2014/A\u001b[39m\u001b[38;5;132;01m{s:02d}\u001b[39;00m\u001b[38;5;132;01m{r}\u001b[39;00m\u001b[33m.mat\u001b[39m\u001b[33m\"\u001b[39m.format(u=base_url, s=subject, r=r)\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     filename = \u001b[43mdata_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m     filenames += filename\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m only_filenames:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\bnci.py:24\u001b[39m, in \u001b[36mdata_path\u001b[39m\u001b[34m(url, path, force_update, update_path, verbose)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdata_path\u001b[39m(url, path=\u001b[38;5;28;01mNone\u001b[39;00m, force_update=\u001b[38;5;28;01mFalse\u001b[39;00m, update_path=\u001b[38;5;28;01mNone\u001b[39;00m, verbose=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata_dl\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBNCI\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_update\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<decorator-gen-481>:12\u001b[39m, in \u001b[36mdata_dl\u001b[39m\u001b[34m(url, sign, path, force_update, verbose)\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\moabb\\datasets\\download.py:160\u001b[39m, in \u001b[36mdata_dl\u001b[39m\u001b[34m(url, sign, path, force_update, verbose)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    159\u001b[39m     known_hash = file_hash(\u001b[38;5;28mstr\u001b[39m(destination))\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m dlpath = \u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43mknown_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdestination\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogressbar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdownloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m dlpath\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\pooch\\core.py:239\u001b[39m, in \u001b[36mretrieve\u001b[39m\u001b[34m(url, known_hash, fname, path, processor, downloader, progressbar)\u001b[39m\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m downloader \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    237\u001b[39m     downloader = choose_downloader(url, progressbar=progressbar)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m \u001b[43mstream_download\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfull_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mknown_hash\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m known_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    242\u001b[39m     get_logger().info(\n\u001b[32m    243\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mSHA256 hash of downloaded file: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    244\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUse this value as the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mknown_hash\u001b[39m\u001b[33m'\u001b[39m\u001b[33m argument of \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpooch.retrieve\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m         file_hash(\u001b[38;5;28mstr\u001b[39m(full_path)),\n\u001b[32m    248\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\pooch\\core.py:807\u001b[39m, in \u001b[36mstream_download\u001b[39m\u001b[34m(url, fname, known_hash, downloader, pooch, retry_if_failed)\u001b[39m\n\u001b[32m    803\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    804\u001b[39m     \u001b[38;5;66;03m# Stream the file to a temporary so that we can safely check its\u001b[39;00m\n\u001b[32m    805\u001b[39m     \u001b[38;5;66;03m# hash before overwriting the original.\u001b[39;00m\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m temporary_file(path=\u001b[38;5;28mstr\u001b[39m(fname.parent)) \u001b[38;5;28;01mas\u001b[39;00m tmp:\n\u001b[32m--> \u001b[39m\u001b[32m807\u001b[39m         \u001b[43mdownloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpooch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m         hash_matches(tmp, known_hash, strict=\u001b[38;5;28;01mTrue\u001b[39;00m, source=\u001b[38;5;28mstr\u001b[39m(fname.name))\n\u001b[32m    809\u001b[39m         shutil.move(tmp, \u001b[38;5;28mstr\u001b[39m(fname))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\pooch\\downloaders.py:240\u001b[39m, in \u001b[36mHTTPDownloader.__call__\u001b[39m\u001b[34m(self, url, output_file, pooch, check_only)\u001b[39m\n\u001b[32m    238\u001b[39m     progress = \u001b[38;5;28mself\u001b[39m.progressbar\n\u001b[32m    239\u001b[39m     progress.total = total\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:1091\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1093\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[32m   1094\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:980\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) >= amt:\n\u001b[32m    978\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[32m    984\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:904\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    901\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    903\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m904\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    905\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    906\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    907\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    912\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    913\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[32m    914\u001b[39m         \u001b[38;5;28mself\u001b[39m._fp.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\response.py:887\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    884\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read1()\n\u001b[32m    885\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    886\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m887\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\http\\client.py:479\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt > \u001b[38;5;28mself\u001b[39m.length:\n\u001b[32m    477\u001b[39m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[32m    478\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m479\u001b[39m s = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    481\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    482\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[32m    483\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_conn()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Authors: Bruno Aristimunha <b.aristimunha@gmail.com>\n",
    "#\n",
    "# License: BSD (3-clause)\n",
    "\n",
    "import mne\n",
    "\n",
    "from braindecode.datasets import MOABBDataset\n",
    "from braindecode.preprocessing import (\n",
    "    Anonymize,\n",
    "    ApplyHilbert,\n",
    "    Crop,\n",
    "    Filter,\n",
    "    Pick,\n",
    "    Resample,\n",
    "    SetEEGReference,\n",
    "    SetMontage,\n",
    "    preprocess,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef2593ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01T.mat' to file 'C:\\Users\\qkrrk\\mne_data\\MNE-bnci-data\\database\\data-sets\\001-2014\\A01T.mat'.\n",
      "c:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bnci-horizon-2020.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "100%|#####################################| 42.8M/42.8M [00:00<00:00, 13.3GB/s]\n",
      "SHA256 hash of downloaded file: 054f02e70cf9c4ada1517e9b9864f45407939c1062c6793516585c6f511d0325\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n",
      "Downloading data from 'http://bnci-horizon-2020.eu/database/data-sets/001-2014/A01E.mat' to file 'C:\\Users\\qkrrk\\mne_data\\MNE-bnci-data\\database\\data-sets\\001-2014\\A01E.mat'.\n",
      "c:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'bnci-horizon-2020.eu'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "c:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\urllib3\\connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'lampx.tugraz.at'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "100%|#####################################| 43.8M/43.8M [00:00<00:00, 20.6GB/s]\n",
      "SHA256 hash of downloaded file: 53d415f39c3d7b0c88b894d7b08d99bcdfe855ede63831d3691af1a45607fb62\n",
      "Use this value as the 'known_hash' argument of 'pooch.retrieve' to ensure that the file hasn't changed if it is downloaded again in the future.\n"
     ]
    }
   ],
   "source": [
    "dataset = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cb829bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original sampling frequency: 250.0 Hz\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "After resampling: 100.0 Hz\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 165 samples (1.650 s)\n",
      "\n",
      "Applied bandpass filter 4-30 Hz\n"
     ]
    }
   ],
   "source": [
    "# 1. Resample to reduce computational load\n",
    "print(f\"Original sampling frequency: {dataset.datasets[0].raw.info['sfreq']} Hz\")\n",
    "preprocessors_signal = [\n",
    "    Resample(sfreq=100),  # Downsample to 100 Hz\n",
    "]\n",
    "preprocess(dataset, preprocessors_signal)\n",
    "print(f\"After resampling: {dataset.datasets[0].raw.info['sfreq']} Hz\")\n",
    "\n",
    "# 2. Remove power line noise and apply bandpass filter\n",
    "preprocessors_filtering = [\n",
    "    Filter(l_freq=4, h_freq=30),  # Bandpass filter 4-30 Hz\n",
    "]\n",
    "preprocess(dataset, preprocessors_filtering)\n",
    "print(\"Applied bandpass filter 4-30 Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cdb47f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels before pick: 26\n",
      "Channels after pick: 22\n",
      "Original channel names (first 3): ['Fz', 'FC3', 'FC1']\n"
     ]
    }
   ],
   "source": [
    "# 3. Pick only EEG channels\n",
    "preprocessors_channels = [\n",
    "    Pick(picks=\"eeg\"),  # Select only EEG channels\n",
    "]\n",
    "print(f\"Channels before pick: {len(dataset.datasets[0].raw.ch_names)}\")\n",
    "preprocess(dataset, preprocessors_channels)\n",
    "print(f\"Channels after pick: {len(dataset.datasets[0].raw.ch_names)}\")\n",
    "\n",
    "# 4. Rename channels (example - just for demonstration)\n",
    "original_names = dataset.datasets[0].raw.ch_names[:3]\n",
    "print(f\"Original channel names (first 3): {original_names}\")\n",
    "# Note: We won't actually rename to avoid breaking the example,\n",
    "# but this is how you would do it:\n",
    "# preprocessors_rename = [\n",
    "#     RenameChannels(mapping={'C3': 'C3_renamed', 'C4': 'C4_renamed'}),\n",
    "# ]\n",
    "# preprocess(dataset, preprocessors_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c3f5369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Set EEG reference to average\n",
      "Set montage, number of positions: 22\n"
     ]
    }
   ],
   "source": [
    "# 5. Set EEG reference to average\n",
    "preprocessors_reference = [\n",
    "    SetEEGReference(ref_channels=\"average\"),\n",
    "]\n",
    "preprocess(dataset, preprocessors_reference)\n",
    "print(\"Set EEG reference to average\")\n",
    "\n",
    "# 6. Set montage for proper channel positions\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "preprocessors_montage = [\n",
    "    SetMontage(montage=montage, match_case=False, on_missing=\"ignore\"),\n",
    "]\n",
    "preprocess(dataset, preprocessors_montage)\n",
    "print(\n",
    "    f\"Set montage, number of positions: {len(dataset.datasets[0].raw.get_montage().get_positions()['ch_pos'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a86ff5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data duration before crop: 386.9 s\n",
      "Data duration after crop: 60.0 s\n"
     ]
    }
   ],
   "source": [
    "# 7. Crop data to specific time range\n",
    "preprocessors_crop = [\n",
    "    Crop(tmin=0, tmax=60),  # Keep only first 60 seconds\n",
    "]\n",
    "print(f\"Data duration before crop: {dataset.datasets[0].raw.times[-1]:.1f} s\")\n",
    "preprocess(dataset, preprocessors_crop)\n",
    "print(f\"Data duration after crop: {dataset.datasets[0].raw.times[-1]:.1f} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6812de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anonymized measurement information\n"
     ]
    }
   ],
   "source": [
    "# 8. Anonymize measurement information\n",
    "preprocessors_anonymize = [\n",
    "    Anonymize(),\n",
    "]\n",
    "preprocess(dataset, preprocessors_anonymize)\n",
    "print(\"Anonymized measurement information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "011673df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computed signal envelope\n"
     ]
    }
   ],
   "source": [
    "# 9. Compute envelope (useful for some analyses)\n",
    "# Note: This modifies the data, so use carefully\n",
    "preprocessors_envelope = [\n",
    "    ApplyHilbert(envelope=True),\n",
    "]\n",
    "preprocess(dataset, preprocessors_envelope)\n",
    "print(\"Computed signal envelope\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913ec0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Complete Preprocessing Pipeline Example\n",
      "============================================================\n",
      "Original: 250.0 Hz, 386.9 s, 26 channels\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 4 - 30 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 4.00\n",
      "- Lower transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 3.00 Hz)\n",
      "- Upper passband edge: 30.00 Hz\n",
      "- Upper transition bandwidth: 7.50 Hz (-6 dB cutoff frequency: 33.75 Hz)\n",
      "- Filter length: 413 samples (1.652 s)\n",
      "\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "Finding events on: stim\n",
      "48 events found on stim channel stim\n",
      "Event IDs: [1 2 3 4]\n",
      "After preprocessing: 100.0 Hz, 60.0 s, 22 channels\n",
      "\n",
      "Preprocessing complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Complete Preprocessing Pipeline Example\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reload dataset for complete pipeline demonstration\n",
    "dataset_complete = MOABBDataset(dataset_name=\"BNCI2014_001\", subject_ids=[1])\n",
    "\n",
    "# Set montage first (needed for interpolation)\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "\n",
    "complete_pipeline = [\n",
    "    # 1. Set montage\n",
    "    SetMontage(montage=montage, match_case=False, on_missing=\"ignore\"),\n",
    "    # 2. Set reference\n",
    "    SetEEGReference(ref_channels=\"average\"),\n",
    "    # 3. Bandpass filter\n",
    "    Filter(l_freq=4, h_freq=30),\n",
    "    # 4. Downsample\n",
    "    Resample(sfreq=100),\n",
    "    # 5. Select only EEG channels\n",
    "    Pick(picks=\"eeg\"),\n",
    "    # 6. Crop to region of interest\n",
    "    Crop(tmin=0, tmax=60),\n",
    "    # 7. Anonymize\n",
    "    Anonymize(),\n",
    "]\n",
    "\n",
    "print(\n",
    "    f\"Original: {dataset_complete.datasets[0].raw.info['sfreq']} Hz, \"\n",
    "    f\"{dataset_complete.datasets[0].raw.times[-1]:.1f} s, \"\n",
    "    f\"{len(dataset_complete.datasets[0].raw.ch_names)} channels\"\n",
    ")\n",
    "\n",
    "preprocess(dataset_complete, complete_pipeline)\n",
    "\n",
    "print(\n",
    "    f\"After preprocessing: {dataset_complete.datasets[0].raw.info['sfreq']} Hz, \"\n",
    "    f\"{dataset_complete.datasets[0].raw.times[-1]:.1f} s, \"\n",
    "    f\"{len(dataset_complete.datasets[0].raw.ch_names)} channels\"\n",
    ")\n",
    "\n",
    "print(\"\\nPreprocessing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4df37033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from braindecode.datasets import BaseConcatDataset, RawDataset\n",
    "from braindecode.util import create_mne_dummy_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "606e294e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_regression_dataset(\n",
    "    n_fake_recs,\n",
    "    n_fake_chs,\n",
    "    fake_sfreq,\n",
    "    fake_duration,\n",
    "    n_fake_targets,\n",
    "    fake_data_split=[0.6, 0.2, 0.2],\n",
    "):\n",
    "    \"\"\"Generate a fake regression dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_fake_recs : int\n",
    "        Number of fake recordings.\n",
    "    n_fake_chs : int\n",
    "        Number of fake EEG channels.\n",
    "    fake_sfreq : float\n",
    "        Fake sampling frequency in Hz.\n",
    "    fake_duration : float\n",
    "        Fake recording duration in seconds.\n",
    "    n_fake_targets : int\n",
    "        Number of targets.\n",
    "    fake_data_split : list\n",
    "        List of train/valid/test subset fractions.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dataset : BaseConcatDataset object\n",
    "        The generated dataset object.\n",
    "\n",
    "    \"\"\"\n",
    "    datasets = []\n",
    "    for i in range(n_fake_recs):\n",
    "        if i < int(fake_data_split[0] * n_fake_recs):\n",
    "            target_subset = \"train\"\n",
    "        elif i < int((1 - fake_data_split[2]) * n_fake_recs):\n",
    "            target_subset = \"valid\"\n",
    "        else:\n",
    "            target_subset = \"test\"\n",
    "        raw, _ = create_mne_dummy_raw(\n",
    "            n_channels=n_fake_chs, n_times=fake_duration * fake_sfreq, sfreq=fake_sfreq\n",
    "        )\n",
    "\n",
    "        target = np.random.randint(0, 10, n_fake_targets)\n",
    "        for j in range(n_fake_targets):\n",
    "            x = np.sin(2 * np.pi * target[j] * raw.times)\n",
    "            raw._data += np.expand_dims(x, axis=0)\n",
    "\n",
    "        if n_fake_targets == 1:\n",
    "            target = target[0]\n",
    "        fake_description = pd.Series(\n",
    "            data=[target, target_subset], index=[\"target\", \"session\"]\n",
    "        )\n",
    "        datasets.append(RawDataset(raw, fake_description, target_name=\"target\"))\n",
    "\n",
    "    return BaseConcatDataset(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcf88f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=21, n_times=3000\n",
      "    Range : 0 ... 2999 =      0.000 ...    29.990 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "n_fake_rec = 20\n",
    "n_fake_chans = 21\n",
    "fake_sfreq = 100\n",
    "fake_duration = 30\n",
    "n_fake_targets = 1\n",
    "dataset = fake_regression_dataset(\n",
    "    n_fake_recs=n_fake_rec,\n",
    "    n_fake_chs=n_fake_chans,\n",
    "    fake_sfreq=fake_sfreq,\n",
    "    fake_duration=fake_duration,\n",
    "    n_fake_targets=n_fake_targets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f817d4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from braindecode.models import Deep4Net, ShallowFBCSPNet\n",
    "from braindecode.util import set_random_seeds\n",
    "\n",
    "# Choosing a CNN model\n",
    "model_name = \"shallow\"  # 'shallow' or 'deep'\n",
    "\n",
    "# Defining a CNN model\n",
    "if model_name in [\"shallow\", \"Shallow\", \"ShallowConvNet\"]:\n",
    "    model = ShallowFBCSPNet(\n",
    "        n_chans=n_fake_chans,\n",
    "        n_outputs=n_fake_targets,\n",
    "        n_times=fake_sfreq * fake_duration,\n",
    "        n_filters_time=40,\n",
    "        n_filters_spat=40,\n",
    "        final_conv_length=35,\n",
    "    )\n",
    "elif model_name in [\"deep\", \"Deep\", \"DeepConvNet\"]:\n",
    "    model = Deep4Net(\n",
    "        n_chans=n_fake_chans,\n",
    "        n_outputs=n_fake_targets,\n",
    "        n_times=fake_sfreq * fake_duration,\n",
    "        n_filters_time=25,\n",
    "        n_filters_spat=25,\n",
    "        stride_before_pool=True,\n",
    "        n_filters_2=n_fake_chans * 2,\n",
    "        n_filters_3=n_fake_chans * 4,\n",
    "        n_filters_4=n_fake_chans * 8,\n",
    "        final_conv_length=1,\n",
    "    )\n",
    "else:\n",
    "    raise ValueError(f\"{model_name} unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dee9a71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if cuda else \"cpu\"\n",
    "if cuda:\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# Setting a random seed\n",
    "seed = 20200220\n",
    "set_random_seeds(seed=seed, cuda=cuda)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    print('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dfbabe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|##5                                | 3.14M/42.8M [42:33<8:58:21, 1.23kB/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Dilation should equal 1 before conversion, maybe the model is already converted?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mbraindecode\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_fixed_length_windows\n\u001b[32m      3\u001b[39m window_size_samples = fake_sfreq * fake_duration // \u001b[32m3\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_dense_prediction_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m n_preds_per_input = model.get_output_shape()[\u001b[32m2\u001b[39m]\n\u001b[32m      7\u001b[39m windows_dataset = create_fixed_length_windows(\n\u001b[32m      8\u001b[39m     dataset,\n\u001b[32m      9\u001b[39m     start_offset_samples=\u001b[32m0\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     preload=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\qkrrk\\anaconda3\\Lib\\site-packages\\braindecode\\models\\base.py:357\u001b[39m, in \u001b[36mEEGModuleMixin.to_dense_prediction_model\u001b[39m\u001b[34m(self, axis)\u001b[39m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.modules():  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m    356\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mdilation\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m module.dilation == \u001b[32m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (module.dilation == (\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)), (\n\u001b[32m    358\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mDilation should equal 1 before conversion, maybe the model is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    359\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33malready converted?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    360\u001b[39m         )\n\u001b[32m    361\u001b[39m         new_dilation = [\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m]\n\u001b[32m    362\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m axis:  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Dilation should equal 1 before conversion, maybe the model is already converted?"
     ]
    }
   ],
   "source": [
    "from braindecode.preprocessing import create_fixed_length_windows\n",
    "\n",
    "window_size_samples = fake_sfreq * fake_duration // 3\n",
    "model.to_dense_prediction_model()\n",
    "\n",
    "n_preds_per_input = model.get_output_shape()[2]\n",
    "windows_dataset = create_fixed_length_windows(\n",
    "    dataset,\n",
    "    start_offset_samples=0,\n",
    "    stop_offset_samples=0,\n",
    "    window_size_samples=window_size_samples,\n",
    "    window_stride_samples=n_preds_per_input,\n",
    "    drop_last_window=False,\n",
    "    preload=True,\n",
    ")\n",
    "\n",
    "# Splitting windowed data into train, valid and test subsets.\n",
    "splits = windows_dataset.split(\"session\")\n",
    "\n",
    "train_set = splits[\"train\"]\n",
    "valid_set = splits[\"valid\"]\n",
    "test_set = splits[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f309387a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    train_neg_root_mean_squared_error    valid_loss    valid_neg_root_mean_squared_error      lr     dur\n",
      "-------  ------------  -----------------------------------  ------------  -----------------------------------  ------  ------\n",
      "      1       \u001b[36m27.3274\u001b[0m                              \u001b[32m-3.3441\u001b[0m        \u001b[35m2.3827\u001b[0m                              \u001b[31m-1.5429\u001b[0m  0.0010  1.4676\n",
      "      2        \u001b[36m3.5502\u001b[0m                              -4.8593       10.3744                              -3.2199  0.0005  0.3360\n",
      "      3        \u001b[36m3.4020\u001b[0m                              -4.0961        7.7488                              -2.7824  0.0000  0.5363\n"
     ]
    }
   ],
   "source": [
    "from skorch.callbacks import LRScheduler\n",
    "from skorch.helper import predefined_split\n",
    "\n",
    "from braindecode import EEGRegressor\n",
    "from braindecode.training.losses import CroppedLoss\n",
    "\n",
    "batch_size = 4\n",
    "n_epochs = 3\n",
    "optimizer_lr = 0.001\n",
    "optimizer_weight_decay = 0.0\n",
    "regressor = EEGRegressor(\n",
    "    model,\n",
    "    cropped=True,\n",
    "    criterion=CroppedLoss,\n",
    "    criterion__loss_function=torch.nn.functional.mse_loss,\n",
    "    optimizer=torch.optim.AdamW,\n",
    "    optimizer__lr=optimizer_lr,\n",
    "    optimizer__weight_decay=optimizer_weight_decay,\n",
    "    train_split=predefined_split(valid_set),\n",
    "    iterator_train__shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[\n",
    "        \"neg_root_mean_squared_error\",\n",
    "        (\"lr_scheduler\", LRScheduler(\"CosineAnnealingLR\", T_max=n_epochs - 1)),\n",
    "    ],\n",
    "    device=device,\n",
    ")\n",
    "regressor.fit(train_set, y=None, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f7f15e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bci_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
